---
title: "Building and Deploying a Reddit Clone application with the DevSecOps pipeline enhanced by Monitoring and Logging."
datePublished: Sat Dec 23 2023 18:30:00 GMT+0000 (Coordinated Universal Time)
cuid: clqjef8se000108k2309l86bi
slug: building-and-deploying-a-reddit-clone-application-with-the-devsecops-pipeline-enhanced-by-monitoring-and-logging
cover: https://cdn.hashnode.com/res/hashnode/image/upload/v1703418958779/98fcdf35-02d7-4ac2-b6dd-0e9342c7ee2f.jpeg
tags: devsecops-pipeline-monitoring-logging

---

### Introduction:

This project would focus on automating the deployment of a cloud-native infrastructure using Terraform and AWS, specifically leveraging the Elastic Kubernetes Service (EKS). Continuous integration and delivery (CI/CD) would be implemented using Jenkins and ArgoCD, ensuring smooth and efficient deployments.

To ensure the security of the infrastructure, various tools would be utilized. SonarQube and OWASP would be employed for static code analysis and vulnerability scanning, respectively. Trivy would be used for container image scanning, ensuring that any vulnerabilities in the container images are detected.

For monitoring and observability, Prometheus would be used as a monitoring and alerting system, while Grafana would provide visualization and dashboards. Elasticsearch, Fluentd, and Kibana (EFK stack) would be employed for log management and analysis, enabling centralized logging and efficient log searching.

Overall, this project would showcase the integration and utilization of these tools to achieve a secure and scalable cloud-native infrastructure with robust monitoring and observability capabilities.

### Overview:

This project focuses on deploying a Reddit clone application in a cloud-native environment, along with implementing monitoring and logging capabilities. The following tools will be utilized to achieve this:

* **Terraform:** Infrastructure as Code tool for automating the deployment of the application's infrastructure on AWS.
    
* **AWS:** Cloud platform providing the necessary services and resources for hosting the application.
    
* **EKS (Elastic Kubernetes Service):** Managed Kubernetes service on AWS for container orchestration created using the IAC tool Terraform.
    
* **Jenkins:** CI/CD tool for automating the build, test, and deployment processes.
    
* **SonarQube:** Static code analysis tool for ensuring code quality and identifying potential issues.
    
* **Trivy:** Container image vulnerability scanner to detect and mitigate security risks in the application's containers.
    
* **OWASP:** Open Web Application Security Project, which provides a set of best practices for web application security.
    
* **ArgoCD:** Continuous Deployment tool for managing and automating deployments to the EKS cluster.
    
* **Prometheus:** Monitoring and alerting system for collecting metrics and generating alerts based on predefined rules.
    
* **Grafana:** Visualization and dashboard tool for displaying monitoring data in a user-friendly manner.
    
* **Elasticsearch:** Distributed search and analytics engine for storing and indexing logs.
    
* **Fluentd:** Log collector and forwarding agent for aggregating and forwarding logs to Elasticsearch.
    
* **Kibana:** Data visualization and exploration tool for analyzing logs stored in Elasticsearch.
    

### Project Resources:

**GitHub Link:**

[https://github.com/sridhar-modalavalasa/Reddit-Clone-app](https://github.com/sridhar-modalavalasa/Reddit-Clone-app) - CI (Source Code)

[https://github.com/sridhar-modalavalasa/Reddit-Argocd](https://github.com/sridhar-modalavalasa/Reddit-Argocd) - CD (Manifest file code)

[https://github.com/sridhar-modalavalasa/AWS-EKS-TF](https://github.com/sridhar-modalavalasa/AWS-EKS-TF) - Terraform for EKS.

[https://github.com/sridhar-modalavalasa/EFK-Stack](https://github.com/sridhar-modalavalasa/EFK-Stack) - EFK Stack Deployment.

### **Step1: Create IAM User**

Navigate to the **AWS console**

* Create an **IAM** user with **administration access.**
    
* Log in to the AWS Console with the above user.
    
* Create one free-tier EC2 instance with Ubuntu.
    
* Login to the EC2 instance and follow the below steps.
    

### Step2: Aws Configuration

Install the AWS Cli in your EC2 Ubuntu.

**Install AWS CLI:**

```plaintext
curl "https://awscli.amazonaws.com/awscli-exe-linux-x86_64.zip" -o "awscliv2.zip"
unzip awscliv2.zip
sudo ./aws/install
aws --version
aws configure (Configure your Access and Secret key)
```

### **Step3: Terraform for provisioning Jenkins, sonarQube, and Trivy in EC2 Instance**

**Terraform Installation in an EC2 Instance:**

```plaintext
wget https://releases.hashicorp.com/terraform/1.3.7/terraform_1.3.7_linux_amd64.zip
unzip terraform_1.3.7_linux_amd64.zip
mv terraform /usr/local/bin
sudo mv terraform /usr/local/bin
terraform -v
```

![](https://cdn.hashnode.com/res/hashnode/image/upload/v1703408150698/cf1211f9-a30b-4781-b1df-bb2376fc4800.png align="center")

[**main.tf**](http://main.tf/)**:**

```plaintext
resource "aws_instance" "web" {
  ami                    = "ami-0fc5d935ebf8bc3bc"   #change ami id for different region
  instance_type          = "t2.large"
  key_name               = "key"
  vpc_security_group_ids = [aws_security_group.Jenkins-sg.id]
  user_data              = templatefile("./install.sh", {})

  tags = {
    Name = "Jenkins-sonarqube-trivy-vm"
  }

  root_block_device {
    volume_size = 30
  }
}

resource "aws_security_group" "Jenkins-sg" {
  name        = "Jenkins-sg"
  description = "Allow TLS inbound traffic"

  ingress = [
    for port in [22, 80, 443, 8080, 9000, 3000] : {
      description      = "inbound rules"
      from_port        = port
      to_port          = port
      protocol         = "tcp"
      cidr_blocks      = ["0.0.0.0/0"]
      ipv6_cidr_blocks = []
      prefix_list_ids  = []
      security_groups  = []
      self             = false
    }
  ]

  egress {
    from_port   = 0
    to_port     = 0
    protocol    = "-1"
    cidr_blocks = ["0.0.0.0/0"]
  }

  tags = {
    Name = "jenkins-sg"
  }
}
```

[**provider.tf**](http://provider.tf/)**:**

```plaintext
#provider.tf

terraform {
  required_providers {
    aws = {
      source  = "hashicorp/aws"
      version = "~> 5.0"
    }
  }
}

# Configure the AWS Provider
provider "aws" {
  region = "us-east-1"  #change your region
}
```

[**install.sh**](http://install.sh/)**:**

```plaintext
#!/bin/bash
sudo apt update -y
wget -O - https://packages.adoptium.net/artifactory/api/gpg/key/public | tee /etc/apt/keyrings/adoptium.asc
echo "deb [signed-by=/etc/apt/keyrings/adoptium.asc] https://packages.adoptium.net/artifactory/deb $(awk -F= '/^VERSION_CODENAME/{print$2}' /etc/os-release) main" | tee /etc/apt/sources.list.d/adoptium.list
sudo apt update -y
sudo apt install temurin-17-jdk -y
/usr/bin/java --version
curl -fsSL https://pkg.jenkins.io/debian-stable/jenkins.io-2023.key | sudo tee /usr/share/keyrings/jenkins-keyring.asc > /dev/null
echo deb [signed-by=/usr/share/keyrings/jenkins-keyring.asc] https://pkg.jenkins.io/debian-stable binary/ | sudo tee /etc/apt/sources.list.d/jenkins.list > /dev/null
sudo apt-get update -y
sudo apt-get install jenkins -y
sudo systemctl start jenkins
sudo systemctl status jenkins

#install docker
sudo apt-get update
sudo apt-get install docker.io -y
sudo usermod -aG docker ubuntu  
newgrp docker
sudo chmod 777 /var/run/docker.sock
docker run -d --name sonar -p 9000:9000 sonarqube:lts-community

#install trivy
sudo apt-get install wget apt-transport-https gnupg lsb-release -y
wget -qO - https://aquasecurity.github.io/trivy-repo/deb/public.key | gpg --dearmor | sudo tee /usr/share/keyrings/trivy.gpg > /dev/null
echo "deb [signed-by=/usr/share/keyrings/trivy.gpg] https://aquasecurity.github.io/trivy-repo/deb $(lsb_release -sc) main" | sudo tee -a /etc/apt/sources.list.d/trivy.list
sudo apt-get update
sudo apt-get install trivy -y
```

**Terraform commands to provision:**

```plaintext
terraform init
terraform validate
terraform plan
terraform apply --auto-approve
```

![](https://cdn.hashnode.com/res/hashnode/image/upload/v1702183505781/94b500ef-ec65-4032-bef8-84bf625f4db9.png?auto=compress,format&format=webp align="left")

The EC2 instance Jenkins-sonarqube-trivy-vm is created by Terraform with Jenkins, Sonarqube, and Trivy as userdata for the EC2 instance, which is installed during the creation of the EC2 instance.

Take the public IP address of the EC2 instance, as shown in the below image.

```plaintext
Public IPV4 address>:8080. #For accessing Jenkins
```

```plaintext
sudo cat /var/lib/jenkins/secrets/initialAdminPassword
```

![](https://cdn.hashnode.com/res/hashnode/image/upload/v1703408434245/78d3a337-ea91-4264-83ca-1d48b847170e.png align="center")

![](https://cdn.hashnode.com/res/hashnode/image/upload/v1703408454459/f8211dd1-bd14-4590-8362-db210dbdf8d3.png align="center")

Unlock Jenkins using an administrative password and install the suggested plugins.

![](https://cdn.hashnode.com/res/hashnode/image/upload/v1702184009718/220fd0e7-8677-45b0-bcd4-864ca6140f0f.png?auto=compress,format&format=webp align="left")

![](https://cdn.hashnode.com/res/hashnode/image/upload/v1702184057274/24c6d381-fd6a-480f-9765-6c193b18f9b3.png?auto=compress,format&format=webp align="left")

![](https://cdn.hashnode.com/res/hashnode/image/upload/v1703408520558/10673f56-98bc-43b8-8faa-07beb5765f16.png align="left")

Create a user, click save, and continue.

Jenkins Getting Started Screen.

![](https://cdn.hashnode.com/res/hashnode/image/upload/v1702184154349/77e112a9-9681-4a30-9bb4-4da534f71347.png?auto=compress,format&format=webp align="left")

![](https://cdn.hashnode.com/res/hashnode/image/upload/v1703408660756/645b3bff-ecfe-4216-9aae-86008d252540.png align="center")

**Check Sonarqube container in EC2 Instance**

The sonarqube we provisioned in an EC2 instance using Terraform in a Docker container.

![](https://cdn.hashnode.com/res/hashnode/image/upload/v1703408707300/8378fe4f-7d72-49fe-adbc-68692bf68d80.png align="center")

```plaintext
<Public IPV4 address>:9000. #For accessing Sonarqube
```

![](https://cdn.hashnode.com/res/hashnode/image/upload/v1703408809407/8e746d3d-27e5-4cf7-9fbf-9fc6651eafc2.png align="center")

Enter your username and password, click on login, and change your password.

```plaintext
username admin
password admin
```

![](https://cdn.hashnode.com/res/hashnode/image/upload/v1703408848267/7c906f21-4af7-4827-bbab-27f43fdedda7.png align="center")

Update the new password. This is the Sonar Dashboard, as shown below.

![](https://cdn.hashnode.com/res/hashnode/image/upload/v1703408881074/4c8d91e3-2794-4b84-95a2-748f3538545f.png align="center")

**Check Trivy version**

Check the Trivy version in an Ec2 instance.

![](https://cdn.hashnode.com/res/hashnode/image/upload/v1703408955807/c161c648-b8fd-4998-9362-0aa79dc46d9f.png align="center")

### **Step 4: Install Plugins like JDK, Sonarqube Scanner, NodeJs, and OWASP Dependency Check**

Goto Manage **Jenkins** →**Plugins** → **Available Plugins**

![](https://cdn.hashnode.com/res/hashnode/image/upload/v1702184807613/2f98168e-8595-4e9c-9ccc-04f5c18894dd.png?auto=compress,format&format=webp align="left")

**Install below plugins**

1: Eclipse Temurin Installer (Install without restart)

2: SonarQube Scanner (Install without restart)

3: Sonar Quality Gates (Install Without restart)

4: Nodejs (Without restart)

![](https://cdn.hashnode.com/res/hashnode/image/upload/v1703409105880/8800595a-c2ac-43ef-95ef-f6b6c3988e43.png align="center")

### **4B: Configure Java and Nodejs in Global Tool Configuration**

Goto Manage **Jenkins** → **Tools** → Install **JDK (17)** and **NodeJs (16)**. Click on **Apply** and **Save**

![](https://cdn.hashnode.com/res/hashnode/image/upload/v1702185224674/852f608f-54b8-4d82-8f74-766101241a31.png?auto=compress,format&format=webp align="left")

Choose the option **install from** [**adoptium.net**](http://adoptium.net/)

![](https://cdn.hashnode.com/res/hashnode/image/upload/v1703409241799/80af0890-ebe4-41f8-b6ba-56a182ee8360.png align="center")

### **Step 5: Configure Sonar Server in Manage Jenkins**

Grab the public IP address of your EC2 instance.

Sonarqube works on Port 9000, so &lt;Public IP&gt;:9000.

Go to your Sonarqube server.

Click on **Administration** → **Security** → **Users** → Click on **Tokens** and **Update Token**, → Give it a name, and click on **Generate Token**

![](https://cdn.hashnode.com/res/hashnode/image/upload/v1702185366020/fe4e754a-e0ad-4317-99e8-50884fa07296.png?auto=compress,format&format=webp align="left")

click on update Token

![](https://cdn.hashnode.com/res/hashnode/image/upload/v1694160866134/49f34dd2-de41-455c-aee0-f1ffe13d8488.png?auto=compress,format&format=webp&auto=compress,format&format=webp&auto=compress,format&format=webp&auto=compress,format&format=webp&auto=compress,format&format=webp align="left")

Create a token with a name and generate

![](https://cdn.hashnode.com/res/hashnode/image/upload/v1703409364340/794fad9b-b98c-43b1-b263-f2adaf983744.png align="center")

copy Token

Goto **Jenkins Dashboard** → **Manage Jenkins** → **Credentials** → Add **secret text**. It should look like this

![](https://cdn.hashnode.com/res/hashnode/image/upload/v1702186101219/307a7eac-9b0f-47f1-a7c1-3379c21ae0b0.png?auto=compress,format&format=webp align="left")

![](https://cdn.hashnode.com/res/hashnode/image/upload/v1694161147409/35b423f8-e7e4-402e-895b-cd1869b8a170.png?auto=compress,format&format=webp&auto=compress,format&format=webp&auto=compress,format&format=webp&auto=compress,format&format=webp&auto=compress,format&format=webp align="left")

You will see this page once you click on create

![](https://cdn.hashnode.com/res/hashnode/image/upload/v1703409426798/f80a867a-a625-4e0e-9171-81f58db10461.png align="center")

Now, go to Dashboard → **Manage Jenkins** → **System** and add something like the below image. Copy the **private IP address** of the instance as well.

![](https://cdn.hashnode.com/res/hashnode/image/upload/v1702185941846/21f3a1bb-b082-4266-b77f-ce8f21ce43cb.png?auto=compress,format&format=webp align="left")

Click on Apply and Save.

**The Configure System option** is used in Jenkins to configure different server

**Global Tool Configuration** is used to configure different tools that we install using Plugins

We will install a sonar scanner in the tools.

![](https://cdn.hashnode.com/res/hashnode/image/upload/v1702186043630/afe376eb-6242-4f12-ac73-2bc744c05f98.png?auto=compress,format&format=webp align="left")

In the Sonarqube Dashboard, add a quality gate as well.

In the sonar interface, create the quality gate as shown below:

Click on the **quality gate, then create.**

![](https://cdn.hashnode.com/res/hashnode/image/upload/v1702186397756/2fb60e8b-4ceb-433b-bcf7-7187a2b26f90.png?auto=compress,format&format=webp align="left")

![](https://cdn.hashnode.com/res/hashnode/image/upload/v1702186456129/748c72ea-42d8-48dc-a398-e8354df72917.png?auto=compress,format&format=webp align="left")

Click on the **save** option.

In the Sonarqube Dashboard, Create **Webhook** option as shown in below:

**Administration--&gt; Configuration--&gt;Webhooks**

![](https://cdn.hashnode.com/res/hashnode/image/upload/v1702186163006/74900198-c406-4564-b7d6-33daaf8a81e0.png?auto=compress,format&format=webp align="left")

Click on **Create**

![](https://cdn.hashnode.com/res/hashnode/image/upload/v1702186192291/45a3aa58-701c-423d-99b5-78c6087e57b6.png?auto=compress,format&format=webp align="left")

Add details:

```plaintext
<http://jenkins-private-ip:8080>/sonarqube-webhook/
```

### **Step 6: Install OWASP Dependency Check Plugins**

Go to **Dashboard** → **Manage Jenkins** → **Plugins** → **OWASP Dependency-Check**. Click on it and install it without restarting.

![](https://cdn.hashnode.com/res/hashnode/image/upload/v1694162570631/a0da6454-e85a-4e27-908a-255b024bf834.png?auto=compress,format&format=webp&auto=compress,format&format=webp&auto=compress,format&format=webp&auto=compress,format&format=webp&auto=compress,format&format=webp align="left")

First, we configured the plugin, and next, we had to configure the Tool

Goto **Dashboard** → **Manage Jenkins** → **Tools** →

![](https://cdn.hashnode.com/res/hashnode/image/upload/v1702187136757/19f8c6e8-a1d2-4eba-b9c0-d109d7b04015.png?auto=compress,format&format=webp align="left")

Click on **Apply** and **save** here.

Now go to **Configure** → Pipeline and add this stage to your pipeline and build.

Let's go to our pipeline and add the script to our pipeline script.

```plaintext
pipeline{
    agent any
    tools{
        jdk 'jdk17'
        nodejs 'node16'
    }
    environment {
        SCANNER_HOME=tool 'sonar-scanner'
    }
    stages {
        stage('clean workspace'){
            steps{
                cleanWs()
            }
        }
        stage('Checkout from Git'){
            steps{
                git branch: 'main', url: 'https://github.com/sridhar-modalavalasa/Reddit-Clone-app.git'
            }
        }
        stage("Sonarqube Analysis "){
            steps{
                withSonarQubeEnv('sonar-server') {
                    sh ''' $SCANNER_HOME/bin/sonar-scanner -Dsonar.projectName=Reddit \
                    -Dsonar.projectKey=Reddit '''
                }
            }
        }
        stage("quality gate"){
           steps {
                script {
                    waitForQualityGate abortPipeline: false, credentialsId: 'Sonar-token' 
                }
            } 
        }
        stage('Install Dependencies') {
            steps {
                sh "npm install"
            }
        }
        stage('OWASP FS SCAN') {
            steps {
                dependencyCheck additionalArguments: '--scan ./ --disableYarnAudit --disableNodeAudit', odcInstallation: 'DP-Check'
                dependencyCheckPublisher pattern: '**/dependency-check-report.xml'
            }
        }
        stage('TRIVY FS SCAN') {
            steps {
                sh "trivy fs . > trivyfs.txt"
            }
        }
    }
}
```

![](https://cdn.hashnode.com/res/hashnode/image/upload/v1703410393483/cce1a883-efee-4655-950d-0d18970c8557.png align="center")

Click on Build now, and you will see the stage view like this:

![](https://cdn.hashnode.com/res/hashnode/image/upload/v1703410426917/de44816e-14e5-4fbc-a420-56d9d7f27203.png align="center")

To see the report, you can go to Sonarqube Server and go to Projects.

![](https://cdn.hashnode.com/res/hashnode/image/upload/v1703410485656/360a7210-464a-4142-82b5-aa25085d23b3.png align="center")

You can see the report has been generated, and the status shows as passed. You can see that there are 4.5k lines it has scanned. To see a detailed report, you can go to issues.

![](https://cdn.hashnode.com/res/hashnode/image/upload/v1703410462591/55d7f993-69fc-4e56-a747-8209406cdfbd.png align="center")

You will see that in status, a graph will also be generated for vulnerabilities and there is an option for dependency checking, as shown below.

![](https://cdn.hashnode.com/res/hashnode/image/upload/v1703410835733/f46d0457-b89a-417a-9e8c-6c1583fabe8c.png align="center")

### **Step 7: Docker Image Build and Push**

We need to install the Docker tool on our system.

Go to **Dashboard** → **Manage Plugins** → **Available plugins** → Search for **Docker** and install these plugins.

![](https://cdn.hashnode.com/res/hashnode/image/upload/v1702187503440/4e287534-ef71-40c5-b9d0-0a40bcd3978e.png?auto=compress,format&format=webp align="left")

Now, goto **Dashboard** → **Manage Jenkins** → **Tools** →

![](https://cdn.hashnode.com/res/hashnode/image/upload/v1702187546212/135dee74-244f-4049-b226-44ed20eb827f.png?auto=compress,format&format=webp align="left")

Now go to the Dockerhub repository to generate a token and integrate with Jenkins to push the image to the specific repository.

![](https://cdn.hashnode.com/res/hashnode/image/upload/v1702187650285/87ffeda0-8f6f-4bc1-a3a6-ec2ba593ca25.png?auto=compress,format&format=webp align="left")

If you observe, there is no repository related to reddit.

There is an icon with the first letter of your name.

Click on that **My Account,** --&gt; **Settings --&gt; Create a new token** and copy the token.

![](https://cdn.hashnode.com/res/hashnode/image/upload/v1702187861896/cdcbfb78-f2c0-42bb-8112-2306fe2f1bd0.png?auto=compress,format&format=webp align="left")

Goto **Jenkins Dashboard** → **Manage Jenkins** → **Credentials** → Add **secret text**. It should look like this:

![](https://cdn.hashnode.com/res/hashnode/image/upload/v1702187999216/9c11946b-5457-4463-88dc-92eb502a3c9c.png?auto=compress,format&format=webp align="left")

Add this stage to Pipeline Script.

```plaintext
stage("Docker Build & Push"){
            steps{
                script{
                   withDockerRegistry(credentialsId: 'dockerhub', toolName: 'docker'){ 
                       sh "docker build -t reddit ."
                       sh "docker tag reddit shreedhar4037/reddit:latest "
                       sh "docker push shreedhar4037/reddit:latest "
                    }
                }
            }
        }
        stage("TRIVY"){
            steps{
                sh "trivy image shreedhar4037/reddit:latest > trivy.txt" 
            }
        }
```

You will be able to view the output in the Jenkins pipeline and output upon successful execution.

![](https://cdn.hashnode.com/res/hashnode/image/upload/v1703411194396/4dbc22cd-c7e5-4c21-aa1a-5936cda16096.png align="center")

![](https://cdn.hashnode.com/res/hashnode/image/upload/v1703411222679/3023a307-9433-453e-b538-03e62657e03e.png align="center")

![](https://cdn.hashnode.com/res/hashnode/image/upload/v1703411386001/f2467edb-0463-4114-be81-2c8c6b77ccf9.png align="center")

When you log in to Dockerhub, you will see a new image is created.

![](https://cdn.hashnode.com/res/hashnode/image/upload/v1703411358956/2da40171-d5d9-4204-af17-9f408f0b64e6.png align="center")

### **Step 8: Creation of EKS Cluster with Terraform and ArgoCD Setup**

GitHub Link: [https://github.com/sridhar-modalavalasa/AWS-EKS-TF](https://github.com/sridhar-modalavalasa/AWS-EKS-TF)

Below is the structure I used in this demo with the required modules. For storing the state file in a remote bucket.

![](https://cdn.hashnode.com/res/hashnode/image/upload/v1703411590963/fd84fc56-ec8d-42e3-9922-ae8a89d5f29a.png align="center")

Below are the bucket details after creating the resources. We are storing our state file in a remote location in a S3 bucket.

![](https://cdn.hashnode.com/res/hashnode/image/upload/v1703411739728/c832bae4-bd9e-4005-b577-a7331a82d2f5.png align="center")

![](https://cdn.hashnode.com/res/hashnode/image/upload/v1703411644948/d1eaf2fd-9060-4a84-ab85-0825fc3788fa.png align="center")

```plaintext
terraform init
```

![](https://cdn.hashnode.com/res/hashnode/image/upload/v1703411821375/50bdd64b-29a9-4b96-a9ae-f7208bf81584.png align="center")

```plaintext
terraform validate
```

![](https://cdn.hashnode.com/res/hashnode/image/upload/v1703411865674/1eab692c-20d1-4ecd-a1cc-b09aa8934ce7.png align="center")

```plaintext
terraform plan
```

![](https://cdn.hashnode.com/res/hashnode/image/upload/v1703411883476/23d5eacd-bdce-4265-8037-05fb4b69b5e7.png align="center")

![](https://cdn.hashnode.com/res/hashnode/image/upload/v1703411890754/e404fd72-8bc4-4edb-b5e9-d5dd0aa7e431.png align="center")

```plaintext
terraform apply --auto-approve
```

![](https://cdn.hashnode.com/res/hashnode/image/upload/v1703411913735/47c4f3a0-16ab-431b-a70a-b1bbcee995c1.png align="center")

![](https://cdn.hashnode.com/res/hashnode/image/upload/v1703411928574/9e469830-2aa0-43a3-8f1b-c31356e91a9d.png align="center")

![](https://cdn.hashnode.com/res/hashnode/image/upload/v1703411962717/47b3a343-b627-4315-b2ee-0227a23ad3ea.png align="center")

As we mentioned above, we have successfully stored state files in a remote location.

![](https://cdn.hashnode.com/res/hashnode/image/upload/v1703412010450/ec20c808-d218-4d0a-bd6b-b1ff80f5ae8a.png align="center")

With the help of the below command, we can update the Kube config in your cli. So that you can be able to use the cluster.

```plaintext
aws eks update-kubeconfig --name <cluster-name> --region <name>
kubectl get nodes
```

![](https://cdn.hashnode.com/res/hashnode/image/upload/v1703412268923/8e35f3c8-46c6-4fce-8a41-45f003d95bda.png align="center")

**Now let's install ArgoCD in the EKS Cluster.**

```plaintext
kubectl create ns Argocd
# This will create a new namespace, argocd, where Argo CD services and application resources will live.
kubectl create namespace argocd
kubectl apply -n argocd -f https://raw.githubusercontent.com/argoproj/argo-cd/stab
```

**Download Argo CD CLI:**

```plaintext
curl -sSL -o argocd-linux-amd64 https://github.com/argoproj/argo-cd/releases/latest/download/argocd-linux-amd64
sudo install -m 555 argocd-linux-amd64 /usr/local/bin/argocd
```

**Access The Argo CD API Server:**

* By default, the Argo CD API server is not exposed with an external IP. To access the API server,
    
* Choose one of the following techniques to expose the Argo CD API server:
    
    * Service Type Load Balancer
        
    * Port Forwarding
        

**Let's go with Service Type Load Balancer.**

```plaintext
# Change the argocd-server service type to LoadBalancer.
kubectl patch svc argocd-server -n argocd -p '{"spec": {"type": "LoadBalancer"}}'
```

**List the resources in the namespace:**

```plaintext
kubectl get svc -n argocd
kubectl get pods 0n argocd -o wide
```

![](https://cdn.hashnode.com/res/hashnode/image/upload/v1703412471218/da1d5853-4e35-4562-a71a-6bcc04fd1a8d.png align="center")

**Get the load balancer URL:**

Pickup the load balancer URL in svc section of argocd-server and paste it into the web to get the UI as shown below image:

![](https://cdn.hashnode.com/res/hashnode/image/upload/v1702189158105/55accaa0-66e9-4a1e-90bd-ce260a0f561c.png?auto=compress,format&format=webp align="left")

**Login Using The CLI:**

```plaintext
argocd admin initial-password -n argocd
```

Login with the admin and Password in the above you will get an interface as shown below:

![](https://cdn.hashnode.com/res/hashnode/image/upload/v1703412625228/31f27d6e-eb22-4656-a7f2-daa82aff81b4.png align="center")

**Click on New App:**

* Application name: your choice
    
* project name: default
    

**Enter the Repository URL, set path to ./, Cluster URL to** [**kubernetes.default.svc**](https://kubernetes.default.svc/)**, the namespace to default and click save.**

The GitHub URL is the Kubernetes manifest files, which I have stored, and the pushed image is used in the Kubernetes deployment files.

GitHub Link: [https://github.com/sridhar-modalavalasa/Reddit-Argocd](https://github.com/sridhar-modalavalasa/Reddit-Argocd)

![](https://cdn.hashnode.com/res/hashnode/image/upload/v1703412824813/61bd2ef7-c45f-47ae-a271-d5779705ed5a.png align="center")

**You should see below once you're done with the details.**

![](https://cdn.hashnode.com/res/hashnode/image/upload/v1703412851426/66eb61fc-6320-4ec6-8391-5cea37f05750.png align="center")

![](https://cdn.hashnode.com/res/hashnode/image/upload/v1703412872008/c5bca23c-098b-478e-894f-de4085ab8f77.png align="center")

**You can see the pods running in the EKS Cluster related to reddit application.**

![](https://cdn.hashnode.com/res/hashnode/image/upload/v1703412905469/a8388caf-fe20-4160-9a8e-f7c66fa0dece.png align="center")

We can see the out-of-pods using the load balancer URL of the Reddit app service. Copy and paste the URL.

With the above load balancer, you will be able to see the output as shown in the below image.

![](https://cdn.hashnode.com/res/hashnode/image/upload/v1703413026257/980eb75c-2dd3-44fe-b0d8-e99e36e015ec.png align="center")

### **Step 9: Install Helm & Monitoring K8S using Prometheus and Grafana.**

On Kubernetes Master, install the helm.

```plaintext
curl -fsSL -o get_helm.sh https://raw.githubusercontent.com/helm/helm/main/scripts/get-helm-3
chmod 700 get_helm.sh
./get_helm.sh
helm version --client
```

![](https://cdn.hashnode.com/res/hashnode/image/upload/v1703413291764/defc505b-a411-4ca0-b8f2-9ed2f26310c0.png align="center")

We need to add the Helm Stable Charts for your local client. Execute the below command:

```plaintext
helm repo add stable https://charts.helm.sh/stable
```

Add Prometheus Helm repo:

```plaintext
helm repo add prometheus-community https://prometheus-community.github.io/helm-charts
```

Create Prometheus namespace

```plaintext
kubectl create ns argocd
```

#### **Install kube-Prometheus-stack:**

Below is the command to install kube-prometheus-stack. The helm repo kube-stack-Prometheus (formerly Prometheus-operator) comes with a Grafana deployment embedded.

```plaintext
helm install stable prometheus-community/kube-prometheus-stack -n prometheus
```

![](https://cdn.hashnode.com/res/hashnode/image/upload/v1703413556545/db48addd-2a72-49a5-b573-770e260f71ab.png align="center")

Let's check if the Prometheus and Grafana pods are running or not

```plaintext
kubectl get all -n prometheus
```

![](https://cdn.hashnode.com/res/hashnode/image/upload/v1703413616428/787ffa7a-5f91-4cce-950c-add6c46884a3.png align="center")

```plaintext
kubectl get svc -n prometheus
```

![](https://cdn.hashnode.com/res/hashnode/image/upload/v1703413661337/f21bf707-3e39-408e-8cd9-5950795bcc23.png align="center")

This confirms that Prometheus and Grafana have been installed successfully using Helm.

To make Prometheus and Grafana available outside the cluster, use LoadBalancer or NodePort instead of ClusterIP.

#### **Edit Prometheus Service**

```plaintext
kubectl edit svc stable-kube-prometheus-sta-prometheus -n prometheus
```

![](https://cdn.hashnode.com/res/hashnode/image/upload/v1703413931956/3de7f707-e2d7-485b-9528-34ebf7fb5a88.png align="center")

#### **Edit Grafana Service**

```plaintext
kubectl edit svc stable-grafana -n prometheus
```

Do the same thing for Grafana.

Verify if the service is changed to LoadBalancer and also get the Load Balancer Ports.

![](https://cdn.hashnode.com/res/hashnode/image/upload/v1703414109656/8da26e67-74a1-4257-a446-1da0890b1147.png align="center")

The two services have changed from ClusterIP to Loadbalancer.

Get the Prometheus load balancer URL with port and try as mentioned below.

```plaintext
<loadbalancer>:<port>
```

![](https://cdn.hashnode.com/res/hashnode/image/upload/v1703414245432/6147c77f-217f-46ed-ba12-909fd2b7f665.png align="center")

![](https://cdn.hashnode.com/res/hashnode/image/upload/v1703415223057/9516e621-cde8-4f2d-b701-7949d6f387b2.png align="center")

![](https://cdn.hashnode.com/res/hashnode/image/upload/v1703414358122/8a6a8d31-039a-4aec-9fc5-e02f30254bcb.png align="center")

![](https://cdn.hashnode.com/res/hashnode/image/upload/v1703414367241/e57baa22-f4ed-4694-b9f4-9c6df4cfac53.png align="center")

**Access Grafana UI in the browser**

Now we will check from the Grafana end point as well. Try with the load balancer URL, which is enough to check Grafana UI on the web.

Login to Grafana

```plaintext
UserName: admin 
Password: prom-operator
```

![](https://cdn.hashnode.com/res/hashnode/image/upload/v1703414475511/d7309877-1864-41fa-aa69-71985a69b1b3.png align="center")

**Create a Dashboard in Grafana**

In Grafana, we can create various kinds of dashboards as per our needs.

**How to Create Kubernetes Monitoring Dashboard?**

* For creating a dashboard to monitor the cluster:
    
* Click the '+' button on the left panel and select ‘Import’.
    
* Enter the 15661 dashboard id under [**Grafana.com**](http://grafana.com/) Dashboard.
    
* Click ‘Load’.
    

Select ‘Prometheus’ as the endpoint under the Prometheus data sources drop-down.

![](https://cdn.hashnode.com/res/hashnode/image/upload/v1697482651268/5fc224f1-cf07-46a6-bc18-7c91fe52ac3d.png?auto=compress,format&format=webp align="left")

Click ‘Import’.

This will show the monitoring dashboard for all cluster nodes.

![](https://cdn.hashnode.com/res/hashnode/image/upload/v1703414663827/3fb4fe05-8bd5-46ea-972d-241677036e29.png align="center")

**How to Create Kubernetes Cluster Monitoring Dashboard?**

* For creating a dashboard to monitor the cluster:
    
* Click the '+' button on the left panel and select ‘Import’.
    
* Enter 3119 dashboard ID under [**Grafana.com**](http://grafana.com/) Dashboard.
    
* Click ‘Load’.
    
* Select ‘Prometheus’ as the endpoint under the Prometheus data sources drop-down.
    
* Click ‘Import’.
    

This will show the monitoring dashboard for all cluster nodes

![](https://cdn.hashnode.com/res/hashnode/image/upload/v1703414743420/a768e41d-4997-480f-b203-fc03fa9884c6.png align="center")

**Create a POD Monitoring Dashboard**

* For creating a dashboard to monitor the cluster:
    
* Click the '+' button on the left panel and select ‘Import’.
    
* Enter 6417 dashboard ID under [**Grafana.com**](http://grafana.com/) Dashboard.
    
* Click ‘Load’.
    
* Select ‘Prometheus’ as the endpoint under the Prometheus data sources drop-down.
    
* Click ‘Import’.
    

![](https://cdn.hashnode.com/res/hashnode/image/upload/v1703414780759/7a1c9b65-b5e2-4b85-b3db-2e58a65b9333.png align="center")

### **Step 10: Installation of logging on K8S using ElasticSearch, Fluentd and Kibana.**

Step 1: Clone Your GitHub Repository Begin by cloning your GitHub repository containing the EFK manifest files:

```plaintext
git clone https://github.com/sridhar-modalavalasa/EFK-Stack.git
```

Step 2: Navigate to the EFK Directory Move to the EFK directory in your repository to access the manifest files for deployment:

```plaintext
$ ls -la
```

![](https://cdn.hashnode.com/res/hashnode/image/upload/v1703415207337/7ce76c3d-04a5-4566-82fd-730b7f25dfc7.png align="center")

Step 3: Create EFK Deployment Apply the manifest files to create the EFK stack deployment:

```plaintext
$ kubectl apply -f .
```

![](https://cdn.hashnode.com/res/hashnode/image/upload/v1703415309586/864c4dc4-9db5-48a9-b3d6-261091515875.png align="center")

```plaintext
kubectl get all =n efk-stack
```

![](https://cdn.hashnode.com/res/hashnode/image/upload/v1703415324787/d1818500-3685-4dd0-9926-556b17dd494c.png align="center")

Step4: Enable Kibana Security Ensure that port 5601 is enabled in the Kibana Load Balancer for secure access: (Note: Provide instructions specific to your environment for enabling port 5601)

Step 5: Access Kibana URL Open your web browser and access the Kibana URL to interact with the dashboard.

```plaintext
<loadbalancer url>:<port>
```

Step 6: Create Index Patterns Create index patterns in Kibana by selecting <mark>'*' and '</mark>@[@timestamp](@timestamp)<mark>' to index the log data.</mark>

Step 7: Explore Logs in Kibana Now you can explore and analyze your logs through the user-friendly Kibana dashboard.

![](https://cdn.hashnode.com/res/hashnode/image/upload/v1703415467795/48edab5c-44bb-489d-8991-5968dbabe979.png align="center")

![](https://cdn.hashnode.com/res/hashnode/image/upload/v1703415481753/9f216431-9497-4e3b-94d0-1d721d04f771.png align="center")

![](https://cdn.hashnode.com/res/hashnode/image/upload/v1703415495832/f2e6ff28-8451-4438-bea2-d17558cf5f93.png align="center")

### Conclusion:

The project will demonstrate the deployment of a Reddit clone application in a cloud-native environment using EKS, with automated CI/CD pipelines managed by Jenkins. Additionally, the project will implement monitoring and logging capabilities using Prometheus, Grafana, Elasticsearch, Fluentd, and Kibana, ensuring visibility into the application's performance and facilitating effective troubleshooting and analysis.

**Thank you for reading this post! I hope you find it helpful. If you have any feedback or questions, Please connect with me on LinkedIn at**

[https://www.linkedin.com/in/sridhar-modalavalasa-12b492173/](https://www.linkedin.com/in/sridhar-modalavalasa-12b492173/)

[https://github.com/sridhar-modalavalasa](https://github.com/sridhar-modalavalasa)

**Your feedback is valuable to me. Thank you!**